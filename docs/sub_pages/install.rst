Code and Data
===============================================


.. raw:: html
   
   <i class="fa fa-github"></i> View on and Install via <a
   href="https://github.com/">GitHub (coming soon).</a> 
   <br /> <br />

.. <i class="fa fa-github"></i> View on and Install via <a
.. href="https://anonymous.4open.science/r/Modality-Gap-UAI2022/">Anonymous GitHub.</a> 
.. <br /> <br />



Repo Structure Overview
-----------------------

.. code:: TextLexer

   .
   ├── README.md
   ├── Figure_1_Modality_Gap/
   ├── Figure_2_Cone_Effect/
   ├── Figure_3_Contrastive_Learning/
   ├── Table_1_Implications_CLIP_Zero_Shot/
   ├── Table_2_Implications_CLIP_Fairness/
   ├── util/

We organize the code in the orders of the figures as presented in the
paper. As the folder name indicated, the `Figure_1_Modality_Gap`
folder provides the code for reproducing Figure 1.


Citation
--------

.. code-block:: bibtex

   @InProceedings{
     anonymous2022ModalityGap,
     title={Mind the Gap: Understanding the Modality Gap in Multi-modal Contrastive Representation Learning},
     author={Anonymous},
     booktitle={Under Review},
     year={2022},
     url={https://openreview.net},
     note={Under Review}
   }